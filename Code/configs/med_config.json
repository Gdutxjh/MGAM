{
  "architectures": [
    "BertModel"
  ],
  "attention_probs_dropout_prob": 0.5,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.5,

  "hidden_size": 768, 
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30524,
  "encoder_width": 768,
  "add_cross_attention": true,   
  "seq_max_len": 20,
  "patch_size": 72,
  "patch_size2": 36,
  "mlp_input_size": 1024,
  "mlp_size": 300,

  "MFB_K": 10,
  "MFB_O": 768,
  "MFB_DROPOUT_R": 0.1,
  "FEAT_SIZE": 768,
  "I_GLIMPSES": 2,
  "LSTM_OUT_SIZE": 768,
  "Q_GLIMPSES": 2,
  "HIDDEN_SIZE_MFH": 512,
  "HIGH_ORDER": true,
  "MFB_size": 768,

  "GLIMPSE": 8,
  "BAN_HIDDEN_SIZE": 768,
  "BAN_DROPOUT_R": 0.2,
  "K_TIMES": 3,
  "CLASSIFER_DROPOUT_R": 0.5,
  "BA_HIDDEN_SIZE": 2304,
  "temp": 0.07,
  "IMG_FEAT_SIZE": 768,

  "queue_size": 8192,
  "momentum": 0.995,
  "n_layers": 2,
  "heads": 2
}
